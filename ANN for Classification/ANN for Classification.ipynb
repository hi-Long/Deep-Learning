{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python385jvsc74a57bd082513f59c0d28b90688d7f7275c84cb59de2ed646ae9bf0e80c508bb5b68947e",
   "display_name": "Python 3.8.5 64-bit (conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "source": [
    "## Import dataset"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../Datasets/NYCTaxiFares.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "           pickup_datetime  fare_amount  fare_class  pickup_longitude  \\\n",
       "0  2010-04-19 08:17:56 UTC          6.5           0        -73.992365   \n",
       "1  2010-04-17 15:43:53 UTC          6.9           0        -73.990078   \n",
       "2  2010-04-17 11:23:26 UTC         10.1           1        -73.994149   \n",
       "3  2010-04-11 21:25:03 UTC          8.9           0        -73.990485   \n",
       "4  2010-04-17 02:19:01 UTC         19.7           1        -73.990976   \n",
       "\n",
       "   pickup_latitude  dropoff_longitude  dropoff_latitude  passenger_count  \n",
       "0        40.730521         -73.975499         40.744746                1  \n",
       "1        40.740558         -73.974232         40.744114                1  \n",
       "2        40.751118         -73.960064         40.766235                2  \n",
       "3        40.756422         -73.971205         40.748192                1  \n",
       "4        40.734202         -73.905956         40.743115                1  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>pickup_datetime</th>\n      <th>fare_amount</th>\n      <th>fare_class</th>\n      <th>pickup_longitude</th>\n      <th>pickup_latitude</th>\n      <th>dropoff_longitude</th>\n      <th>dropoff_latitude</th>\n      <th>passenger_count</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2010-04-19 08:17:56 UTC</td>\n      <td>6.5</td>\n      <td>0</td>\n      <td>-73.992365</td>\n      <td>40.730521</td>\n      <td>-73.975499</td>\n      <td>40.744746</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2010-04-17 15:43:53 UTC</td>\n      <td>6.9</td>\n      <td>0</td>\n      <td>-73.990078</td>\n      <td>40.740558</td>\n      <td>-73.974232</td>\n      <td>40.744114</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2010-04-17 11:23:26 UTC</td>\n      <td>10.1</td>\n      <td>1</td>\n      <td>-73.994149</td>\n      <td>40.751118</td>\n      <td>-73.960064</td>\n      <td>40.766235</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2010-04-11 21:25:03 UTC</td>\n      <td>8.9</td>\n      <td>0</td>\n      <td>-73.990485</td>\n      <td>40.756422</td>\n      <td>-73.971205</td>\n      <td>40.748192</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2010-04-17 02:19:01 UTC</td>\n      <td>19.7</td>\n      <td>1</td>\n      <td>-73.990976</td>\n      <td>40.734202</td>\n      <td>-73.905956</td>\n      <td>40.743115</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 120000 entries, 0 to 119999\nData columns (total 8 columns):\n #   Column             Non-Null Count   Dtype  \n---  ------             --------------   -----  \n 0   pickup_datetime    120000 non-null  object \n 1   fare_amount        120000 non-null  float64\n 2   fare_class         120000 non-null  int64  \n 3   pickup_longitude   120000 non-null  float64\n 4   pickup_latitude    120000 non-null  float64\n 5   dropoff_longitude  120000 non-null  float64\n 6   dropoff_latitude   120000 non-null  float64\n 7   passenger_count    120000 non-null  int64  \ndtypes: float64(5), int64(2), object(1)\nmemory usage: 7.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0    80000\n",
       "1    40000\n",
       "Name: fare_class, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "df['fare_class'].value_counts()"
   ]
  },
  {
   "source": [
    "## Calculate the distance traveled"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def haversine_distance(df, lat1, long1, lat2, long2):\n",
    "    \"\"\"\n",
    "    Calculates the haversine distance between 2 sets of GPS coordinates in df\n",
    "    \"\"\"\n",
    "    r = 6371  # average radius of Earth in kilometers\n",
    "       \n",
    "    phi1 = np.radians(df[lat1])\n",
    "    phi2 = np.radians(df[lat2])\n",
    "    \n",
    "    delta_phi = np.radians(df[lat2]-df[lat1])\n",
    "    delta_lambda = np.radians(df[long2]-df[long1])\n",
    "     \n",
    "    a = np.sin(delta_phi/2)**2 + np.cos(phi1) * np.cos(phi2) * np.sin(delta_lambda/2)**2\n",
    "    c = 2 * np.arctan2(np.sqrt(a), np.sqrt(1-a))\n",
    "    d = (r * c) # in kilometers\n",
    "\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "           pickup_datetime  fare_amount  fare_class  pickup_longitude  \\\n",
       "0  2010-04-19 08:17:56 UTC          6.5           0        -73.992365   \n",
       "1  2010-04-17 15:43:53 UTC          6.9           0        -73.990078   \n",
       "2  2010-04-17 11:23:26 UTC         10.1           1        -73.994149   \n",
       "3  2010-04-11 21:25:03 UTC          8.9           0        -73.990485   \n",
       "4  2010-04-17 02:19:01 UTC         19.7           1        -73.990976   \n",
       "\n",
       "   pickup_latitude  dropoff_longitude  dropoff_latitude  passenger_count  \\\n",
       "0        40.730521         -73.975499         40.744746                1   \n",
       "1        40.740558         -73.974232         40.744114                1   \n",
       "2        40.751118         -73.960064         40.766235                2   \n",
       "3        40.756422         -73.971205         40.748192                1   \n",
       "4        40.734202         -73.905956         40.743115                1   \n",
       "\n",
       "    dist_km  \n",
       "0  2.126312  \n",
       "1  1.392307  \n",
       "2  3.326763  \n",
       "3  1.864129  \n",
       "4  7.231321  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>pickup_datetime</th>\n      <th>fare_amount</th>\n      <th>fare_class</th>\n      <th>pickup_longitude</th>\n      <th>pickup_latitude</th>\n      <th>dropoff_longitude</th>\n      <th>dropoff_latitude</th>\n      <th>passenger_count</th>\n      <th>dist_km</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2010-04-19 08:17:56 UTC</td>\n      <td>6.5</td>\n      <td>0</td>\n      <td>-73.992365</td>\n      <td>40.730521</td>\n      <td>-73.975499</td>\n      <td>40.744746</td>\n      <td>1</td>\n      <td>2.126312</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2010-04-17 15:43:53 UTC</td>\n      <td>6.9</td>\n      <td>0</td>\n      <td>-73.990078</td>\n      <td>40.740558</td>\n      <td>-73.974232</td>\n      <td>40.744114</td>\n      <td>1</td>\n      <td>1.392307</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2010-04-17 11:23:26 UTC</td>\n      <td>10.1</td>\n      <td>1</td>\n      <td>-73.994149</td>\n      <td>40.751118</td>\n      <td>-73.960064</td>\n      <td>40.766235</td>\n      <td>2</td>\n      <td>3.326763</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2010-04-11 21:25:03 UTC</td>\n      <td>8.9</td>\n      <td>0</td>\n      <td>-73.990485</td>\n      <td>40.756422</td>\n      <td>-73.971205</td>\n      <td>40.748192</td>\n      <td>1</td>\n      <td>1.864129</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2010-04-17 02:19:01 UTC</td>\n      <td>19.7</td>\n      <td>1</td>\n      <td>-73.990976</td>\n      <td>40.734202</td>\n      <td>-73.905956</td>\n      <td>40.743115</td>\n      <td>1</td>\n      <td>7.231321</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "df['dist_km'] = (haversine_distance(df, 'pickup_latitude', 'pickup_longitude', 'dropoff_latitude', 'dropoff_longitude'))\n",
    "df.head()\n"
   ]
  },
  {
   "source": [
    "## Add datetime column and derived useful statistics"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['EDTdate'] = pd.to_datetime(df['pickup_datetime']) - pd.Timedelta(hours=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0         0\n",
       "1         5\n",
       "2         5\n",
       "3         6\n",
       "4         4\n",
       "         ..\n",
       "119995    6\n",
       "119996    4\n",
       "119997    6\n",
       "119998    1\n",
       "119999    5\n",
       "Name: EDTdate, Length: 120000, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 38
    }
   ],
   "source": [
    "df['EDTdate'].dt.weekday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Hour'] = df['EDTdate'].dt.hour\n",
    "df['AMorPM'] = np.where(df['Hour'] < 12, 0, 1)\n",
    "df['Weekday'] = df['EDTdate'].dt.weekday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "            pickup_datetime  fare_amount  fare_class  pickup_longitude  \\\n",
       "0 2010-04-19 08:17:56+00:00          6.5           0        -73.992365   \n",
       "1 2010-04-17 15:43:53+00:00          6.9           0        -73.990078   \n",
       "2 2010-04-17 11:23:26+00:00         10.1           1        -73.994149   \n",
       "3 2010-04-11 21:25:03+00:00          8.9           0        -73.990485   \n",
       "4 2010-04-17 02:19:01+00:00         19.7           1        -73.990976   \n",
       "\n",
       "   pickup_latitude  dropoff_longitude  dropoff_latitude  passenger_count  \\\n",
       "0        40.730521         -73.975499         40.744746                1   \n",
       "1        40.740558         -73.974232         40.744114                1   \n",
       "2        40.751118         -73.960064         40.766235                2   \n",
       "3        40.756422         -73.971205         40.748192                1   \n",
       "4        40.734202         -73.905956         40.743115                1   \n",
       "\n",
       "    dist_km                   EDTdate  Hour  AMorPM  Weekday  \n",
       "0  2.126312 2010-04-19 04:17:56+00:00     4       0        0  \n",
       "1  1.392307 2010-04-17 11:43:53+00:00    11       0        5  \n",
       "2  3.326763 2010-04-17 07:23:26+00:00     7       0        5  \n",
       "3  1.864129 2010-04-11 17:25:03+00:00    17       1        6  \n",
       "4  7.231321 2010-04-16 22:19:01+00:00    22       1        4  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>pickup_datetime</th>\n      <th>fare_amount</th>\n      <th>fare_class</th>\n      <th>pickup_longitude</th>\n      <th>pickup_latitude</th>\n      <th>dropoff_longitude</th>\n      <th>dropoff_latitude</th>\n      <th>passenger_count</th>\n      <th>dist_km</th>\n      <th>EDTdate</th>\n      <th>Hour</th>\n      <th>AMorPM</th>\n      <th>Weekday</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2010-04-19 08:17:56+00:00</td>\n      <td>6.5</td>\n      <td>0</td>\n      <td>-73.992365</td>\n      <td>40.730521</td>\n      <td>-73.975499</td>\n      <td>40.744746</td>\n      <td>1</td>\n      <td>2.126312</td>\n      <td>2010-04-19 04:17:56+00:00</td>\n      <td>4</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2010-04-17 15:43:53+00:00</td>\n      <td>6.9</td>\n      <td>0</td>\n      <td>-73.990078</td>\n      <td>40.740558</td>\n      <td>-73.974232</td>\n      <td>40.744114</td>\n      <td>1</td>\n      <td>1.392307</td>\n      <td>2010-04-17 11:43:53+00:00</td>\n      <td>11</td>\n      <td>0</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2010-04-17 11:23:26+00:00</td>\n      <td>10.1</td>\n      <td>1</td>\n      <td>-73.994149</td>\n      <td>40.751118</td>\n      <td>-73.960064</td>\n      <td>40.766235</td>\n      <td>2</td>\n      <td>3.326763</td>\n      <td>2010-04-17 07:23:26+00:00</td>\n      <td>7</td>\n      <td>0</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2010-04-11 21:25:03+00:00</td>\n      <td>8.9</td>\n      <td>0</td>\n      <td>-73.990485</td>\n      <td>40.756422</td>\n      <td>-73.971205</td>\n      <td>40.748192</td>\n      <td>1</td>\n      <td>1.864129</td>\n      <td>2010-04-11 17:25:03+00:00</td>\n      <td>17</td>\n      <td>1</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2010-04-17 02:19:01+00:00</td>\n      <td>19.7</td>\n      <td>1</td>\n      <td>-73.990976</td>\n      <td>40.734202</td>\n      <td>-73.905956</td>\n      <td>40.743115</td>\n      <td>1</td>\n      <td>7.231321</td>\n      <td>2010-04-16 22:19:01+00:00</td>\n      <td>22</td>\n      <td>1</td>\n      <td>4</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 43
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "source": [
    "## Separate categorical from continuous columns"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Index(['pickup_datetime', 'fare_amount', 'fare_class', 'pickup_longitude',\n",
       "       'pickup_latitude', 'dropoff_longitude', 'dropoff_latitude',\n",
       "       'passenger_count', 'dist_km', 'EDTdate', 'Hour', 'AMorPM', 'Weekday'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "execution_count": 44
    }
   ],
   "source": [
    "df.columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "cont_cols = ['pickup_latitude', 'pickup_longitude', 'dropoff_latitude', 'dropoff_longitude', 'passenger_count', 'dist_km']\n",
    "cat_cols = ['Hour', 'AMorPM', 'Weekday']\n",
    "y_col = 'fare_class'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[ 4,  0,  0],\n",
       "       [11,  0,  5],\n",
       "       [ 7,  0,  5],\n",
       "       ...,\n",
       "       [14,  1,  6],\n",
       "       [ 4,  0,  1],\n",
       "       [12,  1,  5]], dtype=int64)"
      ]
     },
     "metadata": {},
     "execution_count": 56
    }
   ],
   "source": [
    "df[cat_cols].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[ 4,  0,  0],\n",
       "       [11,  0,  5],\n",
       "       [ 7,  0,  5],\n",
       "       [17,  1,  6],\n",
       "       [22,  1,  4]], dtype=int64)"
      ]
     },
     "metadata": {},
     "execution_count": 58
    }
   ],
   "source": [
    "cats = df[cat_cols].values\n",
    "cats[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'type'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-71-8610ab3cf297>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mconts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcont_cols\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mconts\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'type'"
     ]
    }
   ],
   "source": [
    "conts = df[cont_cols].values\n"
   ]
  },
  {
   "source": [
    "## Convert numpy arrays into tensors"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "<ipython-input-80-207c0efef05e>:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  cats = torch.tensor(cats.clone().detach())\n<ipython-input-80-207c0efef05e>:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  conts = torch.tensor(conts.clone().detach(), dtype=torch.float)\n"
     ]
    }
   ],
   "source": [
    "cats = torch.tensor(cats.clone().detach())\n",
    "conts = torch.tensor(conts.clone().detach(), dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[ 40.7305, -73.9924,  40.7447, -73.9755,   1.0000,   2.1263],\n",
       "        [ 40.7406, -73.9901,  40.7441, -73.9742,   1.0000,   1.3923],\n",
       "        [ 40.7511, -73.9941,  40.7662, -73.9601,   2.0000,   3.3268],\n",
       "        [ 40.7564, -73.9905,  40.7482, -73.9712,   1.0000,   1.8641],\n",
       "        [ 40.7342, -73.9910,  40.7431, -73.9060,   1.0000,   7.2313]])"
      ]
     },
     "metadata": {},
     "execution_count": 88
    }
   ],
   "source": [
    "conts[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.tensor(df[y_col].values)"
   ]
  },
  {
   "source": [
    "## Set an embedding size"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[(24, 12), (2, 1), (7, 4)]"
      ]
     },
     "metadata": {},
     "execution_count": 116
    }
   ],
   "source": [
    "cats_sz = [len(df[i].unique()) for i in df[cat_cols]]\n",
    "emb_sz = [(size, min(50, (size + 1)//2)) for size in cats_sz]\n",
    "emb_sz"
   ]
  },
  {
   "source": [
    "## Define a TabularModel"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TabularModel(nn.Module):\n",
    "\n",
    "    def __init__(self, emb_szs, n_cont, out_sz, layers, p=0.5):\n",
    "        super().__init__()\n",
    "        self.embeds = nn.ModuleList([nn.Embedding(ni, nf) for ni,nf in emb_szs])\n",
    "        self.emb_drop = nn.Dropout(p)\n",
    "        self.bn_cont = nn.BatchNorm1d(n_cont)\n",
    "        \n",
    "        layerlist = []\n",
    "        n_emb = sum((nf for ni,nf in emb_szs))\n",
    "        n_in = n_emb + n_cont\n",
    "        \n",
    "        for i in layers:\n",
    "            layerlist.append(nn.Linear(n_in,i)) \n",
    "            layerlist.append(nn.ReLU(inplace=True))\n",
    "            layerlist.append(nn.BatchNorm1d(i))\n",
    "            layerlist.append(nn.Dropout(p))\n",
    "            n_in = i\n",
    "        layerlist.append(nn.Linear(layers[-1],out_sz))\n",
    "            \n",
    "        self.layers = nn.Sequential(*layerlist)\n",
    "    \n",
    "    def forward(self, x_cat, x_cont):\n",
    "        embeddings = []\n",
    "        for i,e in enumerate(self.embeds):\n",
    "            embeddings.append(e(x_cat[:,i]))\n",
    "        x = torch.cat(embeddings, 1)\n",
    "        x = self.emb_drop(x)\n",
    "        \n",
    "        x_cont = self.bn_cont(x_cont)\n",
    "        x = torch.cat([x, x_cont], 1)\n",
    "        x = self.layers(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "TabularModel(\n",
       "  (embeds): ModuleList(\n",
       "    (0): Embedding(24, 12)\n",
       "    (1): Embedding(2, 1)\n",
       "    (2): Embedding(7, 4)\n",
       "  )\n",
       "  (emb_drop): Dropout(p=0.4, inplace=False)\n",
       "  (bn_cont): BatchNorm1d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (layers): Sequential(\n",
       "    (0): Linear(in_features=23, out_features=200, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): Dropout(p=0.4, inplace=False)\n",
       "    (4): Linear(in_features=200, out_features=100, bias=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (7): Dropout(p=0.4, inplace=False)\n",
       "    (8): Linear(in_features=100, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "metadata": {},
     "execution_count": 159
    }
   ],
   "source": [
    "torch.manual_seed(33)\n",
    "model = TabularModel(emb_sz, conts.shape[1], 2, [200, 100], p=.4)\n",
    "\n",
    "model"
   ]
  },
  {
   "source": [
    "## Defining loss function and optimizer"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "source": [
    "## Performing train/test split"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 60000\n",
    "test_size = 12000\n",
    "\n",
    "cat_train = cats[:batch_size-test_size]\n",
    "cat_test = cats[batch_size-test_size:batch_size]\n",
    "con_train = conts[:batch_size-test_size]\n",
    "con_test = conts[batch_size-test_size:batch_size]\n",
    "y_train = y[:batch_size-test_size]\n",
    "y_test = y[batch_size-test_size:batch_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(y_test)"
   ]
  },
  {
   "source": [
    "## Train the model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch:   1  loss: 0.82981378\n",
      "epoch:  26  loss: 0.83495378\n",
      "epoch:  51  loss: 0.83022541\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-171-eba0f7266fde>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m     \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    243\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    244\u001b[0m                 inputs=inputs)\n\u001b[1;32m--> 245\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    246\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    247\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    143\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    144\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 145\u001b[1;33m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[0;32m    146\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    147\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "epochs = 300\n",
    "losses = []\n",
    "\n",
    "for i in range(epochs):\n",
    "    i+=1\n",
    "    y_pred = model(cat_train, con_train)\n",
    "    loss = criterion(y_pred, y_train)\n",
    "    losses.append(loss)\n",
    "    \n",
    "    # a neat trick to save screen space:\n",
    "    if i%25 == 1:\n",
    "        print(f'epoch: {i:3}  loss: {loss.item():10.8f}')\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "print(f'epoch: {i:3}  loss: {loss.item():10.8f}') # print the last line\n",
    "print(f'\\nDuration: {time.time() - start_time:.0f} seconds') # print the time elapsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}